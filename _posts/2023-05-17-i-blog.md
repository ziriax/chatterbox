---
layout: post
title:  "From Pythagoras to the Imaginary!"
date:   2023-05-17 16:43:09 +0200
tags: mathematics math geometry geometric algebra Pythagoras complex numbers imaginary
categories: math
---
# Let's demystify $ i$!

<p style="text-align:center;">
  <img src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjrgQk6Q4KCwfS141QOvidzUlKwwAw7X76H2U_IznksAPA4tipkgs6ujwKRji6zltqXkQKcXdVlHSlLzxBk9-vhLkR-A5L-dYEtQJNkp3v9yjqMV2LFFask_Cn8f9VXp_kh-tiU22DwXqeiCj5WlpV6YJ-foOsGf-7m9n4AFrdrlyNuJzFiK2YDf6YqKA/w640-h640/_5e11a41c-e620-4be7-9343-014f2f9aa62d.jpg" alt="Cover image"/>
  <br/>
  <small>Cover image generated with Bing AI</small>
</p>

---

## My son Mats has just learned about the **complex numbers** in high school! 

<br/>

I was myself **flabbergasted** when I encountered the **imaginary number** back in 1985. How could you possibly come up with a kind of number called $i$ that ***squares to minus one***?

<br/>

$$\Huge i^2=-1$$

<br/>

At SIGGRAPH 2001 - a conference for professional computed graphics - I learned about **Geometric Algebra.**

<p style="text-align:center;">
<img src="https://www.nvidia.com/content/dam/en-zz/Solutions/events/siggraph/2022/ov-at-siggraph-22-web-modules-2c50-D.jpg" alt="NVIDIA at SIGGRAPH 2022"/>
<br/>
<small>NVIDIA at SIGGRAPH 2022, showing virtual Jensen, my CEO</small>
</p>
<br/>

This is an amazing forgotten framework from the 19th century, that is recently **gaining in popularity** again, because from a mathematical point of view, it is **sheer beauty**.

It **unifies** so many seemingly different topics <small>(*vectors, points, lines, planes, volumes, circles, spheres, complex numbers, quaternions, dual quaternions, determinants, intersections, homogenous coordinates, space-time algebra, spinors, tensors, ...*)</small> into **one coherent system**.

<br/>

## With this, we can actually **construct the imaginary number,** just by **using Pythagoras' theorem** (and some obvious axioms)! 

<br/>

Maybe the amazing Greek could have invented this himself?

<p style="text-align:center;">
<img width="400px" src="https://upload.wikimedia.org/wikipedia/commons/thumb/e/e0/Pythagoras_in_the_Roman_Forum%2C_Colosseum.jpg/414px-Pythagoras_in_the_Roman_Forum%2C_Colosseum.jpg" alt="Pythagoras"/>
<br/>
<small>Pythagoras</small>
</p>

The derivation is **so simple** that any _undergraduate math student_ should be able to grasp it.

When I was lecturing applied math & physics at the video game university [Digital Arts & Entertainment](https://www.digitalartsandentertainment.be/), I remember one student becoming **very emotional after I showed this**. _Something I will remember forever!_

<br/>
<br/>

# Constructing $i$

Let's first introduce the **preliminary knowledge** that kids should already have seen at school, *at least in Belgium for math students age 16.*

To make things simple, let's start with a **2D real coordinate space,** $ \mathbb{R}^2$

The elements in this space are called **vectors**, often written like $ \vec{v}$

Every vector can be represented as a pair of **coordinates** $ (x,y)$, where $x$ and $y$ are real numbers, so $ x \in \mathbb{R}$ and $y \in \mathbb{R}$.

<p style="text-align:center;">
<img src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgMHFnjape0QSixZDB-Fcwmbwz_ANaFqaWpTy2DXr1XEKvQDETw4Ldtf5dlxQMz01LY1AsPm6KJ5w1liBXsVy4Z5bRsKcKzTeiAR3-N-EXdBxV6ct_kbB2-pkNTnJQO8ftJTfIFKrPc4WewYylR42bNt7Hhvn6WelIOHlWiLYb9HTMJNED4o8wuSWRvIg/w400-h266/vector.webp" alt="Vector coordinates"/>
<br/>
<a target="_blank" href="https://vikid.net/share?key=A9hlnNgBuO1Um29jHwYIVKwBSl9u6GVL5fAqCqY2NIQBF40EKiX4rDcPn1kFNW6TN3uU4ifuBvbe8ioYI0e8GwXSbPFTx3oodNZ1vGVxmLkzzaZzqoTT52NeQurumcg8mq3uwdr31W6pKHQhbMoJBMFbgvvo83OKUIui4KgWK7ZzTtjrutf26saxeY23HDEbZt9EWRFYvQzgOy7d0VDMTDKkJEHY">Vector coordinates. Click to play</a>
</p>

> *Coordinates are not required to construct $i$, but that's what kids learn at school.*
> <br/>
> Many students will have seen this as 2D **column or row
matrices**; that's just another name for these things.

<br/>

# Operations on vectors

## We can **add** vectors together.

If $\vec{v_1}=(x_1,y_1)$ and $\vec{v_2}=(x_2,y_2)$ then <br/>
<br/>

$$\large\vec{v_1}+\vec{v_2} = (x_1+x_2,y_1+y_2)$$

<br/>
<br/>

<p style="text-align:center;">
<img src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEj3CgC4vtniIdTqDohAm_cA3xotvZRN7rs5p_Wv6gtMbfzwT_IdhINpUhttZs71xtmWiGhTz1o5r3pClpl3ChF_2_CvqCmO0jBqYDHUlVmum5OuSrByZ689pcIi4BVw_RG8D4rsH9koogssk3GG3XSE3sFsJva68aotbX9Ysbp4B5_r4oTqhixp6R2SoQ/w400-h266/vector-add.webp" alt="Vector addition"/>
<br/>
<a target="_blank" href="https://vikid.net/share?key=A9hlnNgBuO1Um29jHwYIVKwBSlD9rXfdXetmwPGncjmp2URQS9nIAt7B6RifK2QjTQrppUBgRe6Bq3WPflHsPUAByOWw68l5C6ozssvbINv4fr9ywX2DyofYJBSbQ8NtVp7QMIRBlefLFdxE2tcaT3hhDZUMpluamXol9pv6SMy2HlgE2RtI9luQXVSSaR45Y7bbKYbLYTPWDjyvJOodjJqqln1z">Vector addition. Click to play</a>
</p>

<br/>

## We can **multiply** a vector by some **real factor**.

If $\vec{v}=(x,y)$ and $\lambda \in \mathbb{R}$ then <br/>
<br/>

$$\large\vec{v} \lambda = \lambda \vec{v} = (\lambda x,\lambda y)$$

<br/>
<br/>

<p style="text-align:center;">
<img src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhMXv3EwmXK_V-g4at_J1RSGnO4qUhtMBeAhbSb6Uk9wO5nOct_dAlo9PwQSLK7NrO1MUN4rysUHJXR4ZPRxOFUrKEDTNRpHFC1VBaAMeqzLGRKgtT9k7dttmoxGhpz6G60kDIvxoHNsz2KRTvctGu4ezyKy28KGsqZhoXxEkRxIp3sZdw3kBxXf9RchQ/w400-h266/vector%20mul.webp" alt="Vector scaling"/>
<br/>
<a target="_blank" href="https://vikid.net/share?key=A9hlnNgBuO1Um29jHwYIVKwBSl81rU2bceHqI9JZHVA3Nzho47jXO1wy0a6CJPlYvRGVrtM1MmNvSGhMp7LqSefojGFOqOQE4C2vHQ7XW0gCh4yE7WSCSjZgGQzgOBiaZw4bbINVVeG0x5oX6sqAlcZHZQfchedowZge8eclYipMkFNTqDSdtxf12a4qJBvxtfJpX50IDNoJPuL7YzTcoBGydp4Y">Vector scaling. Click to play</a>
</p>

<br/>

## We can measure the **length** of a vector.

If $\vec{v}=(x,y)$ then 
<br/>

$$\large\|{\vec{v}}\| = \sqrt{x^2 + y^2}$$

<br/>

<p style="text-align:center;">
<img src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhhE-Ocmk4iSAdHqKsgI7it_WNsLafWvMvIFoPv3n41Y9D5ba5BkNwKKHb96dzpEcVoRizAl4XfrdUOOjW7A8GKzwbENK3p7Tr6HXA0jx9Hd5dIGDHuhws4hYSX_PEN9BVmC6e0MCQCmxH2BX8-8uAzOH7HESjlwxx2tpSS-KvbXWKnRGK8C-V24TCk8Q/w400-h266/vector-length.webp" alt="Vector length"/>
<br/>
<a target="_blank" href="https://vikid.net/share?key=A9hlnNgBuO1Um29jHwYIVKwBSl7ZtberThEEqsbBdOKmUZobGHtaV8T6azhCCyBdcs7NYXJXnzFzUjlSkvtSQSvo7yjXfWEXKITgFfCyc8uVS8B8RM07ZZcPE40q4zyB9saeiDJjvqlnVVMSIU5R9TeXTR5qIb7pQjquCQO4Rr3zUz4HJ2SFnKlLVq7kBWXERq0A8xOFtT3xQyRVo70ftxBFIfkc">Vector length. Click to play</a>
</p>

<br/>

This is called the **Euclidean** norm, named after **Euclid**, another great Greek fellow. His books were a standard reference for _thousands of years_, even in the 19th century!

<p style="text-align:center;">
<img width="400px" src="https://upload.wikimedia.org/wikipedia/commons/a/ac/Byrne1.png"/>
<br/>
<small>Euclid's elements</small>
</p>

That's what all math students learn, so far so good.

<br/>
<br/>

# Where's the product on the vectors? 
Students then typically learn the **inner product** (aka scalar or dot product) between vectors, and in 3D the **cross product**. 

We also learn that you **can't divide vectors**.

But let's think out of the box, and try to **define a product on vectors** that works mostly like the wonderful **product on numbers**. 

This product is called the **geometric product**, and was discovered in the 19th century, but _forgotten_ due to several unfortunate circumstances.

<p style="text-align:center;">
<img height="250px" src="https://upload.wikimedia.org/wikipedia/commons/6/6c/Hermann_Gra%C3%9Fmann.jpg" alt="Hermann Graßmann"/>
<br/>
<small>Graßmann made the foundations</small>
</p>

<p style="text-align:center;">
<img width="400px" src="https://upload.wikimedia.org/wikipedia/commons/8/84/Highgate_Cemetery_-_East_-_William_Kingdon_Clifford_01.jpg" alt="William Kingdon Clifford"/>
<br/>
<small>Clifford refined it, but died very young</small>
</p>

# Axioms

For every vector $ \vec{u}, \vec{v}, \vec{w} \in \mathbb{R}^2$
, and $ \lambda \in \mathbb{R}$, we want this product to have the following axioms:
<br/>
<br/>

**Associative** (*axiom A*) 

$$\large (\vec{u} \:\vec{v})\vec{w} = \vec{u} (\vec{v} \:\vec{w}) = \vec{u}\: \vec{v}\: \vec{w}$$

<br/>
<br/>

**Distributive** *(axiom D)*

$$\large (\vec{u} + \vec{v})\vec{w} = \vec{u}\: \vec{w} +\vec{v}\: \vec{w}$$

$$\large \vec{w} (\vec{u} + \vec{v}) = \vec{w}\: \vec{u} +\vec{w}\: \vec{v}$$

<br/>
<br/>

**Contraction** *(axiom C)*

$$\large \vec{v}^2 = \|\vec{v}\|^2$$

<br/>
<br/>

**Scaling** *(axiom S)*

$$\large\lambda\vec{v} = \vec{v}\lambda$$

<br/>
<br/>

Note that we don't have **commutativity**, that won't work out.

<br/>

# Properties

These **axioms** are mostly the same as those for the product on numbers, nothing special here.

<br/>

Let's now explore some **properties** of this product.

<br/>

First of all, every vector $\vec{v}$ now has an **inverse**:

$$\large\vec{v}^{-1} = \frac{\vec{v}}{\vec{v}^2}$$

You can easily verify that 

$$\large\vec{v} \: \frac{\vec{v}}{\vec{v}^{-1}} =
\frac{\vec{v}}{\vec{v}^{-1}} \: \vec{v} =
\frac{\vec{v}^2}{\vec{v}^2} = 1$$

<br/>

Next, take two **orthogonal unit** vectors, i.e. vectors with length $1$ that form a **right angle**:

$$\large\hat{a}=(1,0)$$ 

$$\large\hat{b}=(0,1)$$

<br/>

The **hat** is used instead of an arrow to indicate the length is $1$. So 

$$\large\|\hat{a}\|=\|\hat{b}\|=1$$

<br/>

From **axiom C**, we can conclude that:

$$\large\hat{a}^2=\hat{b}^2=1$$

<br/>

Let's now define 

$$\large \vec{c}=\hat{a}+\hat{b}=(1,1)$$

<br/>

Since the vectors are **orthogonal**, this means that **Pythagoras** theorem must be true, so

$$\large\|\vec{c}\|^2=\|\hat{a}\|^2+\|\hat{b}\|^2=1+1=2$$

<br/>

Again using **axiom C**, we can also write that as

$$\large\vec{c}^2=\hat{a}^2+\hat{b}^2=2$$

<br/>

But using **axiom D**, we can expand $\vec{c}^2$ as 

$$\large\vec{c}^2=$$

$$\large(\hat{a}+\hat{b})^2=$$

$$\large(\hat{a}+\hat{b})(\hat{a}+\hat{b})=$$

$$\large\hat{a}^2+\hat{a}\hat{b}+\hat{b}\hat{a}+\hat{b}^2=$$

$$\large1+\hat{a}\hat{b}+\hat{b}\hat{a}+1=$$

$$\large2+\hat{a}\hat{b}+\hat{b}\hat{a}$$

<br/>

So combining

$$\large\vec{c}^2=2$$

and

$$\large\vec{c}^2=2+\hat{a}\hat{b}+\hat{b}\hat{a}$$

gives:

$$\large2=2+\hat{a}\hat{b}+\hat{b}\hat{a} $$

$$\large\iff $$

$$\large0=\hat{a}\hat{b}+\hat{b}\hat{a} $$

$$\large\iff $$

$$\large\hat{a}\hat{b} = - \hat{b}\hat{a} $$

<br/>

For **orthogonal unit vectors** at least, it seems the product is **anti-commutative.**

<br/>

> Alternatively, you might conclude that $ \hat{a}\hat{b} = \hat{b}\hat{a} = 0$.
> <br/>
> This reasoning would lead to the **inner product**, but that's ***not associative***, so violates our axiom A.

<br/>

# What is it?

So what kind of **geometric entity** is this product? We don't know, but we can apply the axioms again to explore it's properties.

For example, let's square $ \hat{a}\hat{b}$. 

Using **axiom A** and **S** and the **anti-commutative** property we derived above, we get

$$\large(\hat{a}\hat{b})^2= $$

$$\large(\hat{a}\hat{b})(\hat{a}\hat{b})= $$

$$\large(-\hat{b}\hat{a})(\hat{a}\hat{b})= $$

$$\large-\hat{b}(\hat{a}\hat{a})\hat{b}= $$

$$\large-\hat{b}(1)\hat{b}= $$

$$\large-\hat{b}\hat{b}= $$

$$\large-1$$

<br/>

So here you have it:
<br/>
<br/>
<br/>

$$\Huge i^2=-1$$

<br/>

with 

$$\huge i=\hat{a}\hat{b}$$

<br/>
<br/>
<br/>

The imaginary number requires **no imagination**, just _4 axioms for a product and Pythagoras_!

<br/>

> Wouldn't it be fantastic if a similar derivation would be included in **every undergraduate math textbook**?

<br/>

# What's next?

We could now continue exploring the **many beautiful properties** of this product, but then this blog post would become a book. 

We already have great resources for learning geometric algebra, like [bivector.net](https://bivector.net)

One last thing we want to show, is that the geometric product of ***any*** two orthogonal unit vectors in the 2D plane will result in the ***same*** imaginary number.

<br/>

Take two vectors

$$\large\vec{v_1}=(x_1,y_1)$$

$$\large\vec{v_2}=(x_2,y_2)$$

<br/>

We can write these as a **linear combination** of our orthogonal unit vectors:

$$\large\vec{v_1}=x_1 \hat{a} + y_1 \hat{b}$$

$$\large\vec{v_2}=x_2 \hat{a} + y_2 \hat{b}$$

<br/>

Let's calculate the geometric product:

$$\large\vec{v_1}\vec{v_2}=$$

$$\large (x_1 \hat{a} + y_1 \hat{b})(x_2 \hat{a} + y_2 \hat{b})=$$

$$\large x_1 x_2\hat{a}^2+ x_1 y_2 \hat{a} \hat{b} + y_1 x_2 \hat{b}\hat{a} + y_1 y_2 \hat{b}^2$$

<br/>

We already know that $ \hat{a}^2=\hat{b}^2=1$ and $\hat{a}\hat{b}=-\hat{b}\hat{a}$, so

$$\large x_1 x_2\hat{a}^2+ x_1 y_2 \hat{a} \hat{b} + y_1 x_2 \hat{b} \hat{a} + y_1 y_2 \hat{b}^2=$$

$$\large x_1 x_2 + x_1 y_2 \hat{a} \hat{b} - y_1 x_2 \hat{a} \hat{b} + y_1 y_2=$$

$$\large(x_1 x_2 + y_1 y_2 ) + (x_1 y_2  - y_1 x_2 )\hat{a} \hat{b}=$$

$$\large(x_1 x_2 + y_1 y_2 ) + i \: (x_1 y_2  - y_1 x_2 )$$

<br/>

The first term

$$\large x_1 x_2 + y_1 y_2 $$ 

is the well known **inner product** <small>_(aka dot or scalar product)_</small>, often written as 

$$\Large \vec{v_1} \cdot \vec{v_2}$$

We know this is equal to 

$$\large\|\vec{v_1}\|\|\vec{v_2}\|\cos\theta$$

with $\theta$ the angle between the vectors

<br/>

The second term 

$$\large i \: (x_1 y_2  - y_1 x_2)$$

is the **signed area** of the **parallelogram** spanned by the two vectors multiplied by $i$, and is equal to

$$\large i \: \|\vec{v_1}\|\|\vec{v_2}\|\sin\theta$$

<br/>

This is also equal to $i$ times the determinant of the two vectors:

$$\large i\:\begin{vmatrix}x_1&y_1\\x_2&y_2\end{vmatrix}$$

<br/>

We don"t have a name for this in classical algebra, but in geometric algebra this is called the **outer product** <small>_(aka wedge or exterior product)_</small>, and it is written as

$$\Large \vec{v_1} \wedge \vec{v_2}$$

<br/>

$\vec{v_1} \wedge \vec{v_2}$ is called a **bi-vector**. If you interpret a **vector** as an **oriented line segment**, then a **bi-vector** can be seen as an **oriented plane segment**.

<p style="text-align:center;">
  <img height="400px" src="https://upload.wikimedia.org/wikipedia/commons/9/92/Wedge_product.JPG" alt="bi-vectors"/>
  <br/>
  <a target="_blank" href="https://en.wikipedia.org/wiki/Bivector">bi-vector on Wikipedia</a>
</p>

<br/>

With these, we can now **write** the **geometric product** simply as

$$\Large \vec{v_1} \: \vec{v_2} = \vec{v_1} \cdot \vec{v_2} + \vec{v_1} \wedge \vec{v_2}$$

<br/>

$$= \large\|\vec{v_1}\|\|\vec{v_2}\|(\cos\theta + i\:\sin\theta)$$

<br/>

If we now pick **any two orthogonal unit vectors** for $\hat{v_1}$ and $\hat{v_2}$, we get 

$$\large\|\hat{v_1}\|=1 \:\:\: \large\|\hat{v_2}\|=1 \:\:\:$$

$$\large\theta=\frac{\pi}{2} \:\:\: \large\cos\theta = 0 \:\:\: \large\sin\theta=1$$

<br/>

Using these, our product **simplifies** to

$$\Large\hat{v_1}\:\hat{v_2}= 0 + i\:1 =i $$

<br/>

This means that the geometric product between **any two orthogonal unit vectors** results in $ i$.

There is only one $i$ in the 2D plane, but in Euclidean 3D space, **we have an infinite  amount of imaginary numbers**. We will usually pick 3 of them, corresponding to 3 basis unit bi-vectors, for the XY, YZ, and ZX planes. The **quaternions** just roll out if you continue down that road. 

> Btw **quaternions** are **just double reflections**; they
are **easy**, no magical 4D unit sphere required!

If you want projective geometry, then the **Project Geometric Algebra**
(PGA) gives you a very powerful toolbox, **unifying rotation and
translation**, just using reflections, **easy equations for
intersections**, and much more.

If you want to **unify spheres with planes**, then the **Conformal
geometric algebra** (CGA) is the way to go.

Oh, and it **simplifies** almost **all equations in physics**. Here are
the famous **Maxwell** equations for **electromagnetic** fields. Well,
in Geometric Algebra, it really simplifies to a **single equation!**

<p style="text-align:center;">
  <img src="https://blogger.googleusercontent.com/img/a/AVvXsEjdSTjC7W5LSNO6m-Wpo8nalU4Dd_TvvlWsm4PaB_p7Q2M0hBK-PuEbB0AGlQPSL6iP0ndI5_z7MbwAG1C47hmYQd4c5DsBN_-HbGpkBJrkz0QBVPUw7J_QhFtj2d6G7nhMPLpR_DcWf7BIutgjw5fJmsDVT1rTCp0lyFmDDr4LXNZJWgk-IRRS4HhNxQ=w400-h103" alt="Maxwell's equations"/>
  <br/>
  <a target="_blank" href="http://peeterjoot.com/archives/geometric-algebra/maxwells_ga.pdf">Maxwell's equations expressed with Geometric Algebra</a>
</p>

# Disclaimer

I'm a senior software engineer at [NVIDIA corporation](https://www.nvidia.com), but this blog is **purely personal**, and does not necessarily reflect the opinions of my employer.

*This blog was written with a lot of help from GPT4 at https://chat.openai.com*

